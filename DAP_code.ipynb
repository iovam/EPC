{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71fe755-6f53-4039-8327-d9730c194222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "## Setup\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "### Import all necessary packages to work with Spark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import os, IPython\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from pyspark import __version__ as current_pyspark_version\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bae916-09e9-450c-929b-d3d5b2d5ac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "## Configure the Spark Session\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName('epc_uprn_check')\n",
    "    .config(\"spark.executor.memory\", \"1500m\")\n",
    "    .config(\"spark.executor.cores\", 2)\n",
    "    .config(\"spark.dynamicAllocation.enabled\", 'true')\n",
    "    .config('spark.dynamicAllocation.maxExecutors', 4)\n",
    "    .config('spark.shuffle.service.enabled','true')\n",
    "    .config('spark.ui.showConsoleProgress', 'false')\n",
    "    .enableHiveSupport()\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.html.table_schema\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f274a1e6-0696-4eea-bb4c-3f2d8d3f3a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "## Load the Data\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "# Set the database to use by default\n",
    "spark.sql(\"USE energy_performance_certificate\")\n",
    "\n",
    "# To find what tables are in the database\n",
    "spark.sql(\"SHOW TABLES\").show(truncate=False)\n",
    "\n",
    "\n",
    "# Reading EPC Data from a Hive table using PySpark\n",
    "df_std = spark.read.table(\"all_domestic_certificates_202112_georef_std\")\n",
    "\n",
    "# Reading in the UPRN data to add geographies\n",
    "uprn_df = spark.sql(\"SELECT * FROM national_statistics_uprn_lookup.nsul_jan_2022_gb_std\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58986efd-8348-46f3-836d-6a9e0c0e038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "## Join UPRN to EPC dataframe\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "#Join two spark dataframes with a left join, based on a given column\n",
    "epc_withgeog = (\n",
    "    df_std.join(\n",
    "        uprn_df,\n",
    "        on=df_std.ons_uprn == uprn_df.uprn,\n",
    "        how=\"left\")\n",
    "    .drop(\"uprn\", \"gridgb1e\", \"gridgb1n\", \"pcds\", \"oa11cd\", \"cty21cd\", \"ced17cd\", \"wd19cd\", \n",
    "          \"hlth19cd\", \"ctry11cd\", \"rgn11cd\", \"pcon11cd\", \"eer11cd\", \"ttwa15cd\", \n",
    "          \"itl21cd\", \"npark16cd\", \"lsoa11cd\", \"wz11cd\", \"ccg17cd\", \"bua11cd\", \n",
    "          \"buasd11cd\", \"ruc11ind\", \"oac11ind\", \"lep17cd1\", \"lep17cd2\", \"pfa15cd\", \n",
    "          \"imd19ind\", \"guid\", \"lmk_key\", \"address1\", \"address2\", \"address3\", \n",
    "          \"postcode\", \"building_reference_number\",\"potential_energy_efficiency\", \n",
    "          \"local_authority\", \"constituency\", \"county\", \"lodgement_date\", \"transaction_type\", \n",
    "          \"environment_impact_current\", \"environment_impact_potential\", \n",
    "          \"energy_consumption_current\", \"energy_consumption_potential\", \n",
    "          \"co2_emissions_current\", \"co2_emiss_curr_per_floor_area\", \"co2_emissions_potential\", \n",
    "          \"lighting_cost_current\", \"lighting_cost_potential\", \"heating_cost_current\", \n",
    "          \"heating_cost_potential\", \"hot_water_cost_current\", \"hot_water_cost_potential\", \n",
    "          \"total_floor_area\", \"energy_tariff\", \"mains_gas_flag\", \"floor_level\", \n",
    "          \"flat_top_storey\", \"flat_storey_count\", \"main_heating_controls\", \n",
    "          \"multi_glaze_proportion\", \"glazed_type\", \"glazed_area\", \"extension_count\", \n",
    "          \"number_habitable_rooms\", \"number_heated_rooms\", \"low_energy_lighting\", \n",
    "          \"number_open_fireplaces\", \"hotwater_description\", \"hot_water_energy_eff\", \n",
    "          \"hot_water_env_eff\", \"floor_description\", \"floor_energy_eff\", \"floor_env_eff\", \n",
    "          \"windows_description\", \"windows_energy_eff\", \"windows_env_eff\", \"walls_env_eff\", \n",
    "          \"secondheat_description\", \"sheating_energy_eff\", \"sheating_env_eff\", \"roof_env_eff\", \n",
    "          \"mainheat_description\", \"mainheat_energy_eff\", \"mainheat_env_eff\", \n",
    "          \"mainheatcont_description\", \"mainheatc_energy_eff\", \"mainheatc_env_eff\", \n",
    "          \"lighting_description\", \"lighting_energy_eff\", \"lighting_env_eff\", \"main_fuel\", \n",
    "          \"wind_turbine_count\", \"heat_loss_corridoor\", \"unheated_corridor_length\", \"floor_height\", \n",
    "          \"photo_supply\", \"solar_water_heating_flag\", \"mechanical_ventilation\", \"address\", \n",
    "          \"local_authority_label\", \"constituency_label\", \"posttown\", \"construction_age_band\", \n",
    "          \"lodgement_datetime\", \"tenure\", \"fixed_lighting_outlets_count\", \n",
    "          \"low_energy_fixed_light_count\", \"uprn\", \"uprn_source\", \"guid\", \"ons_uprn_match\", \n",
    "          \"ons_apiversion\", \"ons_confidencescore\",\"ons_dataversion\", \"ons_inputaddress\", \n",
    "          \"ons_matchedformattedaddress\", \"ons_underlyingscore\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f624b5-4579-4aba-ab4c-5777df84af99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Export dataframe to a Hive table\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "#pyspark/hive/delete_table\n",
    "# Delete a HIVE table\n",
    "spark.sql('DROP TABLE IF EXISTS housing_epc.epc_working01')\n",
    "\n",
    "\n",
    "# Write out to a Hive table using saveAsTable\n",
    "table_name = f\"housing_epc.epc_working01\"\n",
    "epc_withgeog.write.saveAsTable(table_name, format=\"parquet\")\n",
    "\n",
    "# Reading Data from a Hive table using PySpark\n",
    "epc_df = spark.sql(\"SELECT * FROM housing_epc.epc_joined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc787bf4-aa97-4418-9eb7-71c824900b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "## Recodes for variables\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "epc_df = epc_df.withColumn(\n",
    "    \"epc_property_group\", f.when((epc_df.property_type == \"House\" )\n",
    "                              |(epc_df.property_type == \"Park house\" )\n",
    "                              |(epc_df.property_type == \"Bungalow\" ), \"House\")\n",
    "                         .when((epc_df.property_type == \"Flat\" )\n",
    "                              |(epc_df.property_type == \"Maisonette\" ), \"Flat\")\n",
    "                        .otherwise (\"voa_x\")\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "epc_df = epc_df.withColumn(\n",
    "    \"epc_built_fm_grp\", f.when((epc_df.built_form == \"Semi-Detached\" ), \"semi-detached\")\n",
    "                         .when((epc_df.built_form == \"Detached\" ), \"detached\")\n",
    "                         .when((epc_df.built_form == \"End-Terrace\" )\n",
    "                              |(epc_df.built_form == \"Mid-Terrace\" )\n",
    "                              |(epc_df.built_form == \"Enclosed End-Terrace\" )\n",
    "                              |(epc_df.built_form == \"Enclosed Mid-Terrace\" ), \"terrace\")\n",
    "                         .when((epc_df.built_form == \"Not Recorded\" ), \"not recorded\")\n",
    "                        .otherwise (\"voa_x\")\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import when\n",
    "epc_df = epc_df.withColumn(\"epc_property_age\", when((epc_df.construction_age_band <= \"1899\")|\n",
    "                                               (epc_df.construction_age_band == \"England and Wales: before 1900\")\n",
    "                                               , 'pre-1900')\n",
    "                                               .when((epc_df.construction_age_band == \"1900\")|\n",
    "                                               (epc_df.construction_age_band == \"1902\")|\n",
    "                                               (epc_df.construction_age_band == \"1910\")|\n",
    "                                               (epc_df.construction_age_band == \"1920\")|\n",
    "                                               (epc_df.construction_age_band == \"1929\")|\n",
    "                                               (epc_df.construction_age_band == \"England and Wales: 1900-1929\")\n",
    "                                               , '1900-1929')\n",
    "                                               .when((epc_df.construction_age_band == \"1930\")|\n",
    "                                               (epc_df.construction_age_band == \"1935\")|\n",
    "                                               (epc_df.construction_age_band == \"1940\")|\n",
    "                                               (epc_df.construction_age_band == \"1950\")|\n",
    "                                               (epc_df.construction_age_band == \"1960\")|\n",
    "                                               (epc_df.construction_age_band == \"1965\")|\n",
    "                                               (epc_df.construction_age_band == \"1969\")|\n",
    "                                               (epc_df.construction_age_band == \"1970\")|\n",
    "                                               (epc_df.construction_age_band == \"1980\")|\n",
    "                                               (epc_df.construction_age_band == \"England and Wales: 1930-1949\")|\n",
    "                                               (epc_df.construction_age_band == \"England and Wales: 1950-1966\")|\n",
    "                                               (epc_df.construction_age_band == \"England and Wales: 1967-1975\")|\n",
    "                                               (epc_df.construction_age_band == \"England and Wales: 1976-1982\")\n",
    "                                               , '1930-1982')\n",
    "                                               .when((epc_df.construction_age_band == \"1983\")|\n",
    "                                               (epc_df.construction_age_band == \"1985\")|\n",
    "                                               (epc_df.construction_age_band == \"1988\")|\n",
    "                                               (epc_df.construction_age_band == \"1992\")|\n",
    "                                               (epc_df.construction_age_band == \"1995\")|\n",
    "                                               (epc_df.construction_age_band == \"2000\")|\n",
    "                                               (epc_df.construction_age_band == \"2002\")|\n",
    "                                               (epc_df.construction_age_band == \"2004\")|\n",
    "                                               (epc_df.construction_age_band == \"2005\")|\n",
    "                                               (epc_df.construction_age_band == \"2006\")|\n",
    "                                               (epc_df.construction_age_band == \"2007\")|\n",
    "                                               (epc_df.construction_age_band == \"2008\")|\n",
    "                                               (epc_df.construction_age_band == \"2009\")|\n",
    "                                               (epc_df.construction_age_band == \"2010\")|\n",
    "                                               (epc_df.construction_age_band == \"2011\")|\n",
    "                                               (epc_df.construction_age_band == \"England and Wales: 1983-1990\")|\n",
    "                                               (epc_df.construction_age_band == \"England and Wales: 1991-1995\")|\n",
    "                                               (epc_df.construction_age_band == \"England and Wales: 1996-2002\")|\n",
    "                                               (epc_df.construction_age_band == \"England and Wales: 2003-2006\")|\n",
    "                                               (epc_df.construction_age_band == \"England and Wales: 2007 onwards\")|\n",
    "                                               (epc_df.construction_age_band == \"England and Wales: 2007-2011\")\n",
    "                                               , '1983-2011')\n",
    "                                               .when((epc_df.construction_age_band == \"England and Wales: 2012 onwards\")|\n",
    "                                               (epc_df.construction_age_band == \"2012\")|\n",
    "                                               (epc_df.construction_age_band == \"2013\")|\n",
    "                                               (epc_df.construction_age_band == \"2014\")|\n",
    "                                               (epc_df.construction_age_band == \"2015\")|\n",
    "                                               (epc_df.construction_age_band == \"2016\")|\n",
    "                                               (epc_df.construction_age_band == \"2017\")|\n",
    "                                               (epc_df.construction_age_band == \"2018\")|\n",
    "                                               (epc_df.construction_age_band == \"2019\")|\n",
    "                                               (epc_df.construction_age_band == \"2020\")|\n",
    "                                               (epc_df.construction_age_band == \"2021\")|\n",
    "                                               (epc_df.construction_age_band == \"2022\")\n",
    "                                               , '2012_onwards')\n",
    "\n",
    "                                               )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d5a1b4-9e1c-4c97-8839-070ab4c4995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Export dataframe to a Hive table\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "#pyspark/hive/delete_table\n",
    "# Delete a HIVE table\n",
    "spark.sql('DROP TABLE IF EXISTS housing_epc.epc_working02')\n",
    "\n",
    "\n",
    "\n",
    "# Write out to a Hive table using saveAsTable\n",
    "table_name = f\"housing_epc.epc_working02\"\n",
    "epc_df.write.saveAsTable(table_name, format=\"parquet\")\n",
    "\n",
    "# Reading Data from a Hive table using PySpark\n",
    "epc_df = spark.sql(\"SELECT * FROM housing_epc.epc_working02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64eaaa1-c240-4d78-80ce-7192ddcd4b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Remove records that have implausible values (that would affect overall EPC score)\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "epc_df = epc_df.filter((epc_df.current_energy_efficiency > 0)\n",
    "                        |(epc_df.potential_energy_efficiency > 0) \n",
    "                        & (epc_df.lighting_cost_current > 0) & (epc_df.lighting_cost_potential > 0) &\n",
    "                        (epc_df.heating_cost_current > 0) & (epc_df.heating_cost_potential > 0) &\n",
    "                        (epc_df.hot_water_cost_current > 0) & (epc_df.building_reference_number > 0) & \n",
    "                        (epc_df.hot_water_cost_potential > 0)\n",
    "                        |(epc_df.current_energy_efficiency < 125))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177294ae-48de-4883-aadf-a13749ed2946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Newest EPC by inspection date\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "#Sort a spark dataframe by the values in a column in ascending order\n",
    "epc_df = epc_df.orderBy([\"ons_uprn\", \"inspection_date\"], ascending=False)\n",
    "\n",
    "epc_df = epc_df.drop_duplicates(['ons_uprn'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d04b34-09d7-48e8-bb5a-6ff05cee11a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Wall/Roof insulation crosstabs\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "#Filter IS IN List values\n",
    "li=[\"Very Good\",\"Average\",\"Good\",\"Poor\",\"Very Poor\"]\n",
    "epc_2 = epc_df.filter(epc_df.walls_energy_eff.isin(li))\n",
    "epc_3 = epc_df.filter(epc_df.roof_energy_eff.isin(li))\n",
    "epc_4 = epc_df.filter(epc_df.walls_env_eff.isin(li))\n",
    "epc_5 = epc_df.filter(epc_df.roof_env_eff.isin(li))\n",
    "\n",
    "\n",
    "#Groups by wall energy efficiency by LA\n",
    "la_wall_sdf = (epc_2.groupBy(\"lad21cd\", \"walls_energy_eff\")\n",
    "                    .agg(f.count(\"walls_energy_eff\"))\n",
    "                    .sort(\"lad21cd\", ascending=True))\n",
    "\n",
    "#Groups by roof energy efficiency by LA to a csv file\n",
    "la_roof_sdf = (epc_3.groupBy(\"lad21cd\", \"roof_energy_eff\")\n",
    "                    .agg(f.count(\"roof_energy_eff\"))\n",
    "                    .sort(\"lad21cd\", ascending=True))\n",
    "\n",
    "#Groups by wall environment efficiency by LA\n",
    "la_wall_env_sdf = (epc_.groupBy(\"lad21cd\", \"walls_env_eff\")\n",
    "                    .agg(f.count(\"walls_env_eff\"))\n",
    "                    .sort(\"lad21cd\", ascending=True))\n",
    "\n",
    "#Groups by roof environment efficiency by LA to a csv file\n",
    "la_roof_env_sdf = (epc_.groupBy(\"lad21cd\", \"roof_env_eff\")\n",
    "                    .agg(f.count(\"roof_env_eff\"))\n",
    "                    .sort(\"lad21cd\", ascending=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d58412-f7f2-44fd-aabd-7051edaf442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Export wall energy efficiency by LA to a csv file\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "# Convert the df you are exporting to Pandas\n",
    "la_wall_sdf.toPandas()\n",
    "\n",
    "# Constuct the file path for the CSV file\n",
    "import os\n",
    "username = os.getenv('HADOOP_USER_NAME') \n",
    "\n",
    "csv_file_path = f'/user/{username}/la_wall_ener_eff.csv'\n",
    "print(csv_file_path)\n",
    "\n",
    "# Coalesce all the data to one partition then write out, overwriting the previous files\n",
    "la_wall_sdf.coalesce(1).write.mode(\"overwrite\").csv(csv_file_path, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f23ba-5c77-4a9c-add8-d28abdb1bae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Export roof environmental efficiency by LA to a csv file\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "# Convert the df you are exporting to Pandas\n",
    "la_roof_env_sdf.toPandas()\n",
    "\n",
    "# Constuct the file path for the CSV file\n",
    "import os\n",
    "username = os.getenv('HADOOP_USER_NAME') \n",
    "\n",
    "csv_file_path = f'/user/{username}/la_roof_env_eff.csv'\n",
    "print(csv_file_path)\n",
    "\n",
    "# Coalesce all the data to one partition then write out, overwriting the previous files\n",
    "la_roof_env_sdf.coalesce(1).write.mode(\"overwrite\").csv(csv_file_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbe2527-76cf-4e2f-ae12-06cfb4f9f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Export roof energy efficiency by LA to a csv file\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "# Convert the df you are exporting to Pandas\n",
    "la_roof_sdf.toPandas()\n",
    "\n",
    "# Constuct the file path for the CSV file\n",
    "import os\n",
    "username = os.getenv('HADOOP_USER_NAME') \n",
    "\n",
    "csv_file_path = f'/user/{username}/la_roof_ener_eff.csv'\n",
    "print(csv_file_path)\n",
    "\n",
    "# Coalesce all the data to one partition then write out, overwriting the previous files\n",
    "la_roof_sdf.coalesce(1).write.mode(\"overwrite\").csv(csv_file_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac6ab8d-59dc-4ef0-b54e-a7b4fa9d7f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "# Export wall environmental efficiency by LA to a csv file\n",
    "# ------------------------------------------------------------------------------------\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "# Convert the df you are exporting to Pandas\n",
    "la_wall_env_sdf.toPandas()\n",
    "\n",
    "# Constuct the file path for the CSV file\n",
    "import os\n",
    "username = os.getenv('HADOOP_USER_NAME') \n",
    "\n",
    "csv_file_path = f'/user/{username}/la_wall_env_eff.csv'\n",
    "print(csv_file_path)\n",
    "\n",
    "# Coalesce all the data to one partition then write out, overwriting the previous files\n",
    "la_wall_env_sdf.coalesce(1).write.mode(\"overwrite\").csv(csv_file_path, header=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810582da-0e4d-4f98-af5c-b13ebe40f21d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbe8a95-bf44-4cf4-a627-21d9414e87ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4340c6-d1c8-4b48-9d6f-2effd51dd4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c1419-2481-4f85-828d-2f67ce3685d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0508ca06-d990-4b26-b2f6-acbe3911d76b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57637fe6-fbcb-4353-90d0-163fe7549689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34928eef-06a1-4089-b989-5c36858f5760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249995d4-ba8c-4358-83b2-29487cdbd6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23347fbd-5f13-4e7e-839e-f007e22d5df4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "r-cpu.4-1.m92",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-1:m92"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
